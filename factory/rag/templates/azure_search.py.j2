from typing import List, Dict, Any, Optional
from azure.search.documents import SearchClient
from azure.search.documents.indexes import SearchIndexClient
from azure.search.documents.indexes.models import (
    SearchIndex, 
    SimpleField, 
    SearchableField, 
    SearchFieldDataType,
    VectorSearch,
    VectorSearchAlgorithmConfiguration,
    HnswAlgorithmConfiguration,
    ExhaustiveKnnAlgorithmConfiguration,
    VectorSearchProfile,
    SemanticSearch,
    SemanticConfiguration,
    SemanticPrioritizedFields,
    SemanticField
)
from azure.core.credentials import AzureKeyCredential

from vector_db.base import VectorDBBase


class AzureAISearch(VectorDBBase):
    """Azure AI Search implementation for vector database"""
    
    def __init__(self, config, embedding_service):
        super().__init__(config, embedding_service)
        self.azure_config = config.azure_search
        self.endpoint = self.azure_config.endpoint
        self.api_key = self.azure_config.api_key
        self.index_name = config.index_name
        self.credential = AzureKeyCredential(self.api_key)
        
        # Initialize clients
        self.index_client = SearchIndexClient(
            endpoint=self.endpoint, 
            credential=self.credential
        )
        self.search_client = None
        
        # Initialize the index
        self._initialize_index()
    
    def _initialize_index(self):
        """Initialize or create the search index"""
        try:
            # Check if index exists
            existing_indexes = list(self.index_client.list_indexes())
            index_exists = any(index.name == self.index_name for index in existing_indexes)
            
            if not index_exists:
                self._create_index()
            
            # Initialize search client
            self.search_client = SearchClient(
                endpoint=self.endpoint,
                index_name=self.index_name,
                credential=self.credential
            )
            
        except Exception as e:
            print(f"Error initializing Azure AI Search index: {str(e)}")
            raise
    
    def _create_index(self):
        """Create a new search index"""
        embedding_dimension = self.embedding_service.get_embedding_dimension()
        
        # Define fields
        fields = [
            SimpleField(name="id", type=SearchFieldDataType.String, key=True),
            SearchableField(name="content", type=SearchFieldDataType.String, analyzer_name="standard.lucene"),
            SimpleField(name="document_id", type=SearchFieldDataType.String, facetable=True, filterable=True),
            SimpleField(name="filename", type=SearchFieldDataType.String, facetable=True, filterable=True),
            SimpleField(name="file_type", type=SearchFieldDataType.String, facetable=True, filterable=True),
            SimpleField(name="chunk_index", type=SearchFieldDataType.Int32, facetable=True, filterable=True),
            SimpleField(name="page", type=SearchFieldDataType.Int32, facetable=True, filterable=True),
            SimpleField(name="title", type=SearchFieldDataType.String, facetable=True, filterable=True),
            SimpleField(name="source", type=SearchFieldDataType.String, facetable=True, filterable=True),
            SearchField(
                name="content_vector",
                type=SearchFieldDataType.Collection(SearchFieldDataType.Single),
                searchable=True,
                vector_search_dimensions=embedding_dimension,
                vector_search_profile_name="my-vector-config"
            ),
        ]
        
        # Configure vector search
        vector_search = VectorSearch(
            algorithms=[
                HnswAlgorithmConfiguration(
                    name="my-hnsw-config",
                    kind="hnsw",
                    parameters={
                        "m": 4,
                        "efConstruction": 400,
                        "efSearch": 500,
                        "metric": self.config.distance_metric
                    }
                ),
                ExhaustiveKnnAlgorithmConfiguration(
                    name="my-exhaustive-knn-config",
                    kind="exhaustiveKnn",
                    parameters={
                        "metric": self.config.distance_metric
                    }
                )
            ],
            profiles=[
                VectorSearchProfile(
                    name="my-vector-config",
                    algorithm_configuration_name="my-hnsw-config"
                )
            ]
        )
        
        # Configure semantic search if available
        semantic_search = None
        if self.azure_config.semantic_configuration:
            semantic_search = SemanticSearch(
                default_configuration_name=self.azure_config.semantic_configuration,
                configurations=[
                    SemanticConfiguration(
                        name=self.azure_config.semantic_configuration,
                        prioritized_fields=SemanticPrioritizedFields(
                            title_field=SemanticField(field_name="title"),
                            content_fields=[SemanticField(field_name="content")]
                        )
                    )
                ]
            )
        
        # Create index
        index = SearchIndex(
            name=self.index_name,
            fields=fields,
            vector_search=vector_search,
            semantic_search=semantic_search
        )
        
        self.index_client.create_index(index)
        print(f"Created Azure AI Search index: {self.index_name}")
    
    async def ingest_documents(self, documents: List[Dict[str, Any]]) -> bool:
        """Ingest documents into Azure AI Search"""
        try:
            documents_to_upload = []
            
            for doc in documents:
                prepared_chunks = self._prepare_document_for_ingestion(doc)
                
                # Embed chunks
                chunk_texts = [chunk['content'] for chunk in prepared_chunks]
                embedded_chunks = await self._embed_chunks(chunk_texts)
                
                # Prepare documents for upload
                for i, (chunk, embedded_chunk) in enumerate(zip(prepared_chunks, embedded_chunks)):
                    doc_id = f"{doc.get('filename', 'doc')}_{i}"
                    
                    document = {
                        "id": doc_id,
                        "content": chunk['content'],
                        "content_vector": embedded_chunk['embedding'],
                        "document_id": chunk['metadata'].get('document_id'),
                        "filename": chunk['metadata'].get('filename'),
                        "file_type": chunk['metadata'].get('file_type'),
                        "chunk_index": chunk['metadata'].get('chunk_index'),
                        "page": chunk['metadata'].get('page'),
                        "title": chunk['metadata'].get('title'),
                        "source": chunk['metadata'].get('source', 'upload')
                    }
                    
                    documents_to_upload.append(document)
            
            # Upload in batches
            batch_size = 1000
            for i in range(0, len(documents_to_upload), batch_size):
                batch = documents_to_upload[i:i + batch_size]
                result = self.search_client.upload_documents(documents=batch)
                
                # Check for errors
                for doc_result in result:
                    if doc_result.succeeded:
                        print(f"Successfully uploaded document: {doc_result.key}")
                    else:
                        print(f"Failed to upload document: {doc_result.key}, Error: {doc_result.error_message}")
            
            return True
            
        except Exception as e:
            print(f"Error ingesting documents: {str(e)}")
            return False
    
    async def search(
        self, 
        query: str, 
        top_k: int = 5, 
        filters: Optional[Dict[str, Any]] = None
    ) -> List[Dict[str, Any]]:
        """Search for similar documents"""
        try:
            # Generate query embedding
            query_embedding = await self.embedding_service.generate_embedding(query)
            
            # Build search query
            search_text = "*"  # Search all documents
            vector_query = {
                "vector": query_embedding,
                "k": top_k,
                "fields": "content_vector"
            }
            
            # Add filters if provided
            filter_string = None
            if filters:
                filter_parts = []
                for key, value in filters.items():
                    if isinstance(value, str):
                        filter_parts.append(f"{key} eq '{value}'")
                    elif isinstance(value, (int, float)):
                        filter_parts.append(f"{key} eq {value}")
                filter_string = " and ".join(filter_parts)
            
            # Perform search
            results = self.search_client.search(
                search_text=search_text,
                vector_queries=[vector_query],
                filter=filter_string,
                top=top_k,
                include_total_count=True
            )
            
            # Format results
            formatted_results = []
            for result in results:
                formatted_result = {
                    "id": result.get("id"),
                    "content": result.get("content"),
                    "score": result.get("@search.score"),
                    "metadata": {
                        "document_id": result.get("document_id"),
                        "filename": result.get("filename"),
                        "file_type": result.get("file_type"),
                        "chunk_index": result.get("chunk_index"),
                        "page": result.get("page"),
                        "title": result.get("title"),
                        "source": result.get("source")
                    }
                }
                formatted_results.append(formatted_result)
            
            return formatted_results
            
        except Exception as e:
            print(f"Error searching documents: {str(e)}")
            return []
    
    async def health_check(self) -> bool:
        """Check if Azure AI Search is healthy"""
        try:
            # Try to get index statistics
            index_stats = self.index_client.get_index_statistics(self.index_name)
            return index_stats is not None
        except Exception as e:
            print(f"Azure AI Search health check failed: {str(e)}")
            return False
    
    async def list_documents(self, limit: int = 100, offset: int = 0) -> List[Dict[str, Any]]:
        """List documents in the database"""
        try:
            results = self.search_client.search(
                search_text="*",
                select="id,filename,document_id,file_type,chunk_index,page,title,source",
                top=limit,
                skip=offset,
                include_total_count=True
            )
            
            documents = []
            for result in results:
                documents.append({
                    "id": result.get("id"),
                    "filename": result.get("filename"),
                    "document_id": result.get("document_id"),
                    "file_type": result.get("file_type"),
                    "chunk_index": result.get("chunk_index"),
                    "page": result.get("page"),
                    "title": result.get("title"),
                    "source": result.get("source")
                })
            
            return documents
            
        except Exception as e:
            print(f"Error listing documents: {str(e)}")
            return []
    
    async def clear_documents(self) -> bool:
        """Clear all documents from the database"""
        try:
            # Delete and recreate index
            self.index_client.delete_index(self.index_name)
            self._create_index()
            return True
        except Exception as e:
            print(f"Error clearing documents: {str(e)}")
            return False
    
    async def get_statistics(self) -> Dict[str, Any]:
        """Get database statistics"""
        try:
            stats = self.index_client.get_index_statistics(self.index_name)
            return {
                "document_count": stats.document_count,
                "storage_size": stats.storage_size,
                "vector_index_size": stats.vector_index_size if hasattr(stats, 'vector_index_size') else None,
                "index_name": self.index_name
            }
        except Exception as e:
            print(f"Error getting statistics: {str(e)}")
            return {}

